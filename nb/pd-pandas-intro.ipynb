{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAML 04 - Pandas Introduction\n",
    "\n",
    "Michal Grochmal <michal.grochmal@city.ac.uk>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapper on top of `NumPy` (and `Matplotlib` to some extent) to make up for the shortcomings\n",
    "of those two libraries when working with real-world data.\n",
    "Instead of working towards efficient\n",
    "numerical computing it attempts to make working with messy data less annoying.\n",
    "The name Pandas comes from the term *Panel data* which is derived from econometrics.\n",
    "\n",
    "Let's import it,\n",
    "and also let's import `NumPy` to see how both libraries work with each other.\n",
    "`pandas.options` holds several variables which are used when displaying the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-10T11:14:24.087336Z",
     "start_time": "2017-05-10T12:14:23.438294+01:00"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## General ideas behind pandas\n",
    "\n",
    "Originally built as an enhanced version of R's `data.frame`,\n",
    "`pandas` incorporates several known APIs into a single structure.\n",
    "The `DataFrame` includes APIs that make it easy for use from different perspectives.\n",
    "\n",
    "* R `data.frame` like structure, extended by multi-indexes\n",
    "* SQL-like joins, without need for external libraries (e.g. `sqldf` in R)\n",
    "* Looks like a spreadsheet (yes, that is intentional)\n",
    "* One can move between two and multidimensional representations (`stack`, `unstack`)\n",
    "* Aggregation across dimensions with `groupby` (similar to SQL)\n",
    "* Enhanced data types with many operations outside pure computation when compared with numpy.\n",
    "\n",
    "You will use `pandas` (rather than `NumPy`) for tasks around messy data, or multiple streams of numeric and/or alpha-numeric data.\n",
    "`pandas` (as most of the libraries in the Python Scientific Stack) is built on top of `NumPy`, and uses the continuous memory and broadcast operations\n",
    "of `NumPy` arrays to boost its performance. It also integrates out-of-the-box graphing functionality through the `matplotlib` API.\n",
    "\n",
    "`pandas` excels at:\n",
    "\n",
    "* Importing data (very resilient compared to `numpy.loadtxt`)\n",
    "* Clean up messy data (`dropna` or `fillna`)\n",
    "* Gain insight into data (`describe`)\n",
    "* Encapsulating different data types within the same structure (`DataFrame`)\n",
    "* Using a plethora of bespoke functions that help with data analytics and summarization\n",
    "\n",
    "Let's use some data about the British isles and the United Kingdom to demonstrate\n",
    "some of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = ['Northern Ireland', 'Scotland', 'Wales', 'England', 'Isle of Man']\n",
    "capital = ['Belfast', 'Edinburgh', 'Cardiff', 'London', 'Douglas']\n",
    "area = np.array([14130, 77933, 20779, 130279, 572])\n",
    "population2017 = np.array([1876695, 5404700, np.nan, 55268100, np.nan])\n",
    "population2011 = np.array([1810863, 5313600, 3063456, 53012456, 83314])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Series\n",
    "\n",
    "The main feature of `pandas` is the `DataFrame` but that is just a collection of `Series` data structures.\n",
    "A `Series` is pretty similar to a `NumPy` array: it is a list of several data of the same data type.\n",
    "The difference is that the `Series` adds labels (an index) to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "series_area = pd.Series(area)\n",
    "series_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_area = pd.Series(area, index=country)\n",
    "uk_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection from the index\n",
    "\n",
    "Selecting from a `Series` works both as a list or as a dictionary.\n",
    "You can say that a `Series.index` maps keys over `Series.values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_area.values, uk_area.values.dtype, uk_area.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the following three forms of indexing produce the same record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "uk_area['Wales'], uk_area[2], uk_area.values[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing works too, so does fancy indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_area[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_area[['Wales', 'Scotland']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorted and unsorted indexes\n",
    "\n",
    "Slicing works on indexes (the labels of the Series)\n",
    "but it is only likely to produce meaningful results if the index is sorted.\n",
    "\n",
    "Note: In older versions of `pandas` slicing over an unsorted index produced an error,\n",
    "this still happens over a multi-index (outlined in a later section).\n",
    "Since we did not care about the order when constructing the data frame our index is unsorted,\n",
    "therefore slicing it will produce strange results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_area['England':'Scotland']  # oops!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we sort the index,\n",
    "the alphabetical order (or actually ASCIIbetical order) of the labels can be used for slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_area.sort_index(inplace=True)\n",
    "uk_area['England':'Scotland']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implicit indexes\n",
    "\n",
    "If you do not define an index you can still select and slice series items.\n",
    "This is because apart from the normal index an implicit, positional, index is created.\n",
    "In other words, every `pandas` series has two indexes: the implicit and the explicit index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_area = pd.Series(area)\n",
    "series_area[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, when the explicit index is non-numeric,\n",
    "the implicit index is used for access.\n",
    "Here is a series with a sorted index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uk_area = pd.Series(area, index=country).sort_index()\n",
    "uk_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time both indexes work in the same fashion but slicing\n",
    "is inconsistent between them:\n",
    "The explicit index includes the last slice element (unlike Python list slicing),\n",
    "whilst the implicit index performs slices in the same way as list slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_area['England':'Scotland']  # Inclusive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_area[0:3]  # Exclusive!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can give us a headache with numerical indexes,\n",
    "therefore `pandas` allows us to choose which index to select from:\n",
    "\n",
    "* `loc` always refers to the explicit index\n",
    "* `iloc` always refers to the implicit index\n",
    "* `ix` is what is actually used when we do plain `[]` indexing (and you would normally not need to write it out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_area = pd.Series(area)\n",
    "series_area.index = [1, 2, 3, 4, 5]\n",
    "series_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_area[1], series_area.loc[1], series_area.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(series_area[1:3]), list(series_area.loc[1:3]), list(series_area.iloc[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, by default, *numeric indexes use the implicit index*.\n",
    "\n",
    "But there's more!\n",
    "If one does not define an index at all `.loc` accesses the implicit index\n",
    "but it uses the explicit index rules of slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_area = pd.Series(area)\n",
    "series_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_area[1], series_area.loc[1], series_area.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(series_area[1:3]), list(series_area.loc[1:3]), list(series_area.iloc[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always cross-check slicing operations and use `.loc` or `.iloc` explicitly.\n",
    "The same rules apply to data frames (seen in a moment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Like an array\n",
    "\n",
    "The `NumPy` vectorized operations, selection and broadcasting work as if we were working on an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "uk_area[uk_area > 20000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the area in square miles instead of square kilometers.\n",
    "\n",
    "$$\n",
    "0.386 \\approx \\frac{1}{1.61^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_area * 0.386"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the total of the UK area in square miles.\n",
    "(The Isle of Man is technically not part of the UK but it is negligible here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(uk_area * 0.386).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More than an array\n",
    "\n",
    "The `Series` aligns the indexes when performing operations.\n",
    "For example what if we would like to know the population growth between 2011 and 2017?\n",
    "\n",
    "Note: Below, `.dropna()` removes rows containing `NULL`s (`NaN`s) fro the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "p11 = pd.Series(population2011, index=country)\n",
    "p17 = pd.Series(population2017, index=country).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we perform the operation the indexes are matched,\n",
    "where a number cannot be found (i.e. the operation contains a `NaN`), pandas automatically inserts a `NaN` (Not a Number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p17 - p11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Frames\n",
    "\n",
    "The `DataFrame` is just a collection of `Series` with a common index.\n",
    "It can be understood as a two-dimensional representation of data,\n",
    "similar to a spreadsheet.  One important thing to note, is that,\n",
    "contrary to a two dimensional `NumPy` array, **indexing a data frame\n",
    "produces the entire column** and not the row.  Yet, indexing it with two descriptors\n",
    "produces the row and the column just like in a `NumPy` array.\n",
    "\n",
    "Let's build a `NumPy` array and a `DataFrame` that look the same.\n",
    "Then we can have a look at how similar operations work on both.\n",
    "Constructing the data frame can be performed in several ways,\n",
    "below is the most common way of using a dictionary of arrays.\n",
    "Each dictionary key-value pair becomes a column (a `Series`).\n",
    "\n",
    "The `NumPy` array, when constructed from a list of arrays,\n",
    "understands each part of the list as a row, therefore we need to transpose it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array([area, capital, population2011, population2017]).T\n",
    "\n",
    "data = pd.DataFrame({'area': area,\n",
    "                     'capital': capital,\n",
    "                     'population 2011': population2011,\n",
    "                     'population 2017': population2017},\n",
    "                    index=country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to note is that the `NumPy` array can only hold one data type.\n",
    "The array casted every data type to a Unicode string.\n",
    "In reality `NumPy` arrays support compound data types\n",
    "but these are considerably more complicated to use the data frames.\n",
    "\n",
    "Data in the data frame got converted too.\n",
    "Each column can have different data types but somewhat the numbers\n",
    "in \"`population 2011`\" and in \"`population 2017`\" look different.\n",
    "The reason behind this being that we cannot have `NaN`s in a `Series` with `int`egers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the same data in `NumPy` and `pandas`, and  we can index it.\n",
    "In `NumPy` a plain index produces a *row*, in `pandas` it produces a *column*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet, there is a twist.\n",
    "Using the implicit index (`.iloc`) produces the same behavior as `NumPy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns with simple names can be accessed as attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, multi-indexing works in the same way as `NumPy`:\n",
    "One provides first the *row* and then the *column*.\n",
    "And slicing works too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc['England', 'area':'capital']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize\n",
    "\n",
    "Data frames have several useful methods to give a feel for the data.\n",
    "With a reasonable amount of data you'd rather not want thousands of rows to\n",
    "be printed.  What you want are methods to give you the data you are after quickly.\n",
    "\n",
    "For example, looking at the beginning or end of sorted values will show outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'area': area,\n",
    "                     'capital': capital,\n",
    "                     'population 2011': population2011,\n",
    "                     'population 2017': population2017},\n",
    "                    index=country).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index is sorted, Therefore we get the countries in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorted by area, should give us the biggest countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values('area').tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The length of a data frame is the number of rows it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `describe` and `info` methods print two distinct types of statistics about the data frame:\n",
    "one gives the statistical view of each column, the other gives you a memory layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data frame can also display plots (using `Matplotlib`) directly.\n",
    "That said, if we want to display the plots within the notebook or style them,\n",
    "we need to perform the `matplotlib` setup ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-talk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the population growth in a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = data[['population 2011', 'population 2017']].plot(kind='bar', figsize=(14, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, on a logarithmic scale, we can see the relation between area and population.\n",
    "\n",
    "Here we also use annotations, this is a `matplotlib` feature.\n",
    "It annotates the string (first argument) over a point on the graph\n",
    "(two coordinates - as a tuple, list or series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = data.plot(kind='scatter', x='population 2011', y='area', loglog=True, figsize=(16, 8))\n",
    "for k, v in data[['population 2011', 'area']].iterrows():\n",
    "    plot.axes.annotate(k, xy=v, xytext=(v[0], v[1]*1.07), ha='center', size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### String methods\n",
    "\n",
    "Another extra feature that does not exist in `NumPy` arrays are methods that work\n",
    "on string content, just like Python string methods.  The `str` object of a `Series`\n",
    "(of a column of a data frame) is used to call string methods on each element, efficiently.\n",
    "The result is either a boolean `Series` that can then be used to retrieve rows from the data frame,\n",
    "or a new string `Series` modified by the operation. Something worthwhile mentioning here is that\n",
    "we should convert the `object` data type to `Strig` for all columns that have String type data.\n",
    "Using string methods on `object` data types still works, but is discouraged!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data['capital'].str.startswith('Be')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several regular expression methods are supported as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.capital.str.contains('[oa]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.index.str.startswith('Eng')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most string Python methods are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['capital'].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To modify the data frame we can assign to a new column.\n",
    "For example, first letter of the capital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['initial'] = data['capital'].str[0].str.upper()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note above that `.str` has been used two times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data\n",
    "\n",
    "More often than not real world data is incomplete in some way.\n",
    "In `NumPy`, and therefore in `pandas`, missing data is represented using NaNs (not a number).\n",
    "NaNs used to be IEEE 754 float NaNs, therefore the data type of a `Series` (or `NumPy` array)\n",
    "should of been either a float or a Python object. Since Pandas version 1.0.0 the NaNs got a\n",
    "big update and now they can be used inside multiple data types of `Series`, you can read more\n",
    "about this major upgrade here: https://pandas.pydata.org/docs/user_guide/missing_data.html#missing-data-na.\n",
    "This is not the case for `NumPy`.\n",
    "\n",
    "`Series` strings are just Python objects,\n",
    "this is contrary to `NumPy`'s arrays; this means that a `Series` or a data frame can hold\n",
    "NULLs (NaNs) for strings.\n",
    "\n",
    "`pandas` data frames have the `dropna` an `fillna` methods that\n",
    "(unsurprisingly) drop or fill in values for NaNs.\n",
    "Dropping can be done by row or column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'area': area,\n",
    "                     'capital': capital,\n",
    "                     'population 2011': population2011,\n",
    "                     'population 2017': population2017},\n",
    "                    index=country).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We lost the data for the Isle of Man, despite the fact that it has data for 2011.\n",
    "Instead we can drop the incomplete columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better.\n",
    "\n",
    "Instead of `NumPy`s `axis=0` and `axis=1`,\n",
    "in `pandas` one can use `axis='index'` and `axis='columns'`.\n",
    "That is, most of the time,\n",
    "some `pandas` functions do accept `axis='row'` and `axis='col'`, beware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Filling NaNs can be performed in three different ways:\n",
    "we can provide a value into `fillna` to substitute the NaNs for (e.g. `.fillna(0)`); or we can use\n",
    "the `method=` argument to use a predefined way of filling the NaNs from the data itself.  The `method=`\n",
    "can be either `pad`/`ffill` which will fill each NaN with a previous (non-NaN) value seen; or it can be\n",
    "`backfill`/`bfill` which will fill a NaN from the next value.\n",
    "Filling can be performed column or row wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = data.fillna(method='ffill', axis='columns')\n",
    "data_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems to have worked but not quite.\n",
    "The numbers look wrong.  We better check the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything got converted to Python objects!\n",
    "That is the caveat of filling NaNs between columns, i.e. we lose data types.\n",
    "We can easily fix this now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fixed = data_full.convert_dtypes()\n",
    "data_fixed.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we can fix it with some data munging.\n",
    "We will separate the columns that need filling from the rest,\n",
    "perform the filling, fix the data types on the reduced data frame and join things back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_partial = data[['population 2011', 'population 2017']].fillna(method='ffill', axis='columns')\n",
    "# the following is slightly overkill for numbers but useful if we have more columns\n",
    "data_partial = data_partial.apply(pd.to_numeric, errors='ignore')\n",
    "data_partial = data_partial.astype(np.integer, errors='ignore')\n",
    "data_full = pd.concat([data[['area', 'capital']], data_partial], axis='columns')\n",
    "data_full.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That appears to be right.\n",
    "But we used a new concept here: we split and joined back two data frames.\n",
    "`pandas` has `.concat`, which allow for joins on `axis`,\n",
    "it accepts a `join` parameter for \"inner\" or \"outer\" joins.\n",
    "The join will happen on the index by default.\n",
    "\n",
    "`pandas` function `merge` has left and right joins using columns as join keys.\n",
    "And finally the data frame itself has a `join` method which can use either\n",
    "`concat` or `merge` directly on the data frames.\n",
    "All three methods are more-or-less interchangeable,\n",
    "their difference is mostly how parameters are passed in.\n",
    "\n",
    "But still, let's look whether the data in the joined frame is as correct\n",
    "as the data types suggest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
