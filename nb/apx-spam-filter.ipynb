{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAML 10 - Spam Filter\n",
    "\n",
    "Michal Grochmal <michal.grochmal@city.ac.uk>\n",
    "\n",
    "We should try at a small project again.  Let's train a spam filter.\n",
    "Apache's [spam assassin][sass] is one off-the-shelf such a spam filter,\n",
    "and we will try to construct something similar.\n",
    "\n",
    "[sass]: https://spamassassin.apache.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Project\n",
    "\n",
    "Get the [public corpus][corpus] from spam assassins's page,\n",
    "and use it to train **and test** a spam classifier.\n",
    "\n",
    "[corpus]: https://spamassassin.apache.org/old/publiccorpus/\n",
    "\n",
    "Easier said than done, therefore attempt to do it following these steps:\n",
    "\n",
    "1.  Get the data, unzip it (`bzip2` is available on any linux or similar),\n",
    "    and MS Widnows will have tools to unzip it (e.g. `peazip`).\n",
    "\n",
    "2.  Familiarize yourself with the data format, this is similar to what\n",
    "    we used in the Gaussian Multinomial classification with the newsgroups.\n",
    "\n",
    "3.  Load the data into a jupyter notebook, and perform TF-IDF.\n",
    "\n",
    "4.  Split the data into training and a test set.\n",
    "\n",
    "5.  Try different classification models, with different hyperparameters.\n",
    "    Use grid search with cross-validation to find good hyperparameters.\n",
    "\n",
    "6.  Evaluate the model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips\n",
    "\n",
    "-   A spam filter cares mostly about a good balance of recall and precision on the spam class.\n",
    "    i.e. you do not want to miss much spam but you do not want to classify valid emails as spam\n",
    "    too often.\n",
    "\n",
    "-   You should try the TF-IDF transformation with and without *stopwords*,\n",
    "    and compare the recall of spam in each case.\n",
    "\n",
    "-   Simple models work particularly well for this data.  kNN and Naive Bayes are known\n",
    "    to do very well on spam classification.  Yet, that does not impede you from trying other\n",
    "    models: Random Forests and Logistic Regression perform very well on one-hot-encoded data\n",
    "    and the TF-IDF encoded data is pretty close to one-hot-encoding when *stopwords* are removed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
