{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05.00 Stats\n",
    "\n",
    "To not make mistakes in analysis a deal of statistical knowledge is required.\n",
    "We will review some statistics and learn a little about distributions in `scipy`.\n",
    "`scipy` is the mathematical library for Python on top of NumPy.\n",
    "It was geared to be the one and only mathematic library for the sciences in Python\n",
    "but it turned out that it would become too big.\n",
    "Libraries flensed from `scipy` often include the `sci` at the beginning of its name,\n",
    "e.g. `scikit-learn` or `scikit-image`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scipy` is comprised of:\n",
    "\n",
    "- Numerical Integration\n",
    "- Function Optimization - used in machine learning routines\n",
    "- Interpolation - e.g. splines\n",
    "- Fast Fourier Transforms\n",
    "- General Signal Processing\n",
    "- Linear Algebra - including Matrix decomposition\n",
    "- Image Processing - as NumPy arrays, used by `scikit-image`\n",
    "- Sparse Matrices - and graphs\n",
    "- Statistics - which is what interests us right now\n",
    "- And a handful of extra things\n",
    "\n",
    "Several of these routines are used in `scikit-learn` and `scikit-image`\n",
    "to produce decomposition and machine learning algorithms.\n",
    "We will look at machine learning from a higher perspective but,\n",
    "for the statistics we need, we can use the `scipy.stats` module.\n",
    "\n",
    "As a quick review let's see a handful of statistical measures\n",
    "(or simply statistics for short) we can perform on data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean\n",
    "\n",
    "$$\\bar{x} = \\frac{1}{N} \\sum_{i=1}^{N} x_i$$\n",
    "\n",
    "#### Variance\n",
    "\n",
    "$$\\sigma^2 = \\frac{1}{N - d} \\sum_{i=1}^{N} (x_i - \\bar{x})^2$$\n",
    "\n",
    "#### Standard Deviation\n",
    "\n",
    "$$\\sigma = \\sqrt{\\frac{1}{N - d} \\sum_{i=1}^{N} (x_i - \\bar{x})^2}$$\n",
    "\n",
    "#### Covariance\n",
    "\n",
    "$$cov(X, Y) = \\sigma_{xy} = \\frac{1}{N - d} \\sum_{i=1}^{N} (x_i - \\bar{x})(y_i - \\bar{y})$$\n",
    "\n",
    "#### Correlation\n",
    "\n",
    "$$corr(X, Y) = r = \\frac{cov(X, Y)}{\\sigma_x \\sigma_y} = \\frac{\\sigma_{xy}}{\\sigma_x \\sigma_y}$$\n",
    "\n",
    "Note: $1/(N-d)$ often becomes just $1/N$ or $1/(N-1)$ in bias-corrected calculations.\n",
    "in other words the most common values for $d$ are $0$ for population\n",
    "statistics and $1$ (or very rarely more) for sample statistics.\n",
    "Bias correction is needed when operating over a sample instead of operating over\n",
    "the entire population.  All below `NumPy` functions (except correlation functions\n",
    "which are not multiplied by $1/N$) accept a `ddof=` (degrees of freedom)\n",
    "argument to perform a sample based calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look why this bias correction makes sense.\n",
    "We will take a dataset of several points in one horizontal axis.\n",
    "The vertical position of the points is merely illustrative\n",
    "of the fact that in a real world we can have only a fraction\n",
    "of all possible measurable conditions.\n",
    "\n",
    "We will assume a normal distribution.\n",
    "The mean is at the center of the data points and\n",
    "a distance of $2$ standard deviations from the mean contains\n",
    "around $95\\%$ of all points - within the dashed lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Population Statistics](da-std-full.svg)\n",
    "\n",
    "<div style=\"text-align:right;\"><sup>da-std-full.svg</sup></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blue points are our full population,\n",
    "there are no more points.\n",
    "Yet if we take a sample from this population we are more likely\n",
    "to sample points from regions there are more blue points in the first place.\n",
    "The green points below are a sample from within the population\n",
    "of all blue points.\n",
    "\n",
    "The mean changes very little - and changes in the value of the mean depend\n",
    "on where on the axis the dataset is positioned, in order to avoid\n",
    "changes to the mean one can center the data at zero\n",
    "as we were doing above with $(x_i - \\bar{x})$.\n",
    "Since changes in mean value can be avoided in most cases\n",
    "there is no need for a degrees of freedom adjustment to the mean.\n",
    "\n",
    "The change in the value of standard deviation is more interesting.\n",
    "The spread of sampled data will always be smaller or equal to\n",
    "the spread of the population.\n",
    "This is exactly due to the reason that we are most likely to sample\n",
    "blue points from the middle rather than from the extremities.\n",
    "The premise is that we are assuming a distribution that is reasonably\n",
    "normal, or to be more exact a univariate distribution - a distribution\n",
    "with a single peak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Population Statistics](da-std-sample.svg)\n",
    "\n",
    "<div style=\"text-align:right;\"><sup>da-std-sample.svg</sup></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create some arrays to play with.\n",
    "One array is a simple range and the others are noise perturbed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([ 0.42656744,  1.34760301,  1.76247459,  2.54394538,  4.25001083,\n",
       "         5.37448213,  5.5951476 ,  6.71161456,  8.04594227,  8.836638  ,\n",
       "        10.37401308, 10.89728014, 12.33849422, 12.76767618, 14.02655641,\n",
       "        14.70839667, 15.52074703, 17.23753479, 18.44489014, 18.62833507,\n",
       "        20.04839567, 21.47013894, 21.65815276, 22.97512403, 23.82185634,\n",
       "        25.26785455, 26.0377071 , 27.36483584, 28.48860728, 28.93587003]),\n",
       " array([ 1.18661367,  1.16547567,  0.14580165,  4.99155547,  4.11994684,\n",
       "         6.55103777,  6.12749731,  9.080279  ,  6.96948181, 10.05920244,\n",
       "        11.70575631, 12.43509519,  9.62236534, 10.61161181, 14.64103517,\n",
       "        15.07336027, 13.54752731, 15.90730184, 20.0211125 , 20.6451752 ,\n",
       "        22.46041344, 19.71946508, 21.1359607 , 21.23087045, 23.24723358,\n",
       "        25.72597371, 26.96254792, 28.7182825 , 27.11062461, 27.01276892]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(30)\n",
    "acv = np.arange(30) + np.random.rand(30) - 0.5\n",
    "acr = np.arange(30) + np.random.rand(30)*5 - 2.5\n",
    "arr, acv, acr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NumPy` has the mean method but implementing it by hand is easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.5\n",
      "14.5\n"
     ]
    }
   ],
   "source": [
    "print(arr.mean())\n",
    "print(arr.sum() / len(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard deviation with zero degrees of freedom is the deviation of our data.\n",
    "With one degree of freedom it is an estimate of a population from which\n",
    "whe data at hand may be a reasonable sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.65544144839919\n",
      "8.803408430829505\n"
     ]
    }
   ],
   "source": [
    "print(arr.std())\n",
    "print(np.std(arr, ddof=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the second value is *bigger*.\n",
    "In the first case we consider all the data as our population.\n",
    "In the second case all our data in `arr` is considered to be just a sample\n",
    "from some population with much more data.\n",
    "That population with more data which we do not know about must\n",
    "have a bigger spread of values.\n",
    "\n",
    "Same story with the variance (since it is just the squared standard deviation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.91666666666667\n",
      "77.5\n"
     ]
    }
   ],
   "source": [
    "print(arr.var())\n",
    "print(arr.var(ddof=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariance method (`cov`) produces the variance of each array on the diagonal\n",
    "and the actual covariance on the interception between the arrays.  i.e.\n",
    "\n",
    "| `np.cov` | arr            | acv           |\n",
    "|:-------- |:-------------- |:------------- |\n",
    "| **arr**  | cov(arr, arr)  | cov(arr, acv) |\n",
    "| **acv**  | cov(acv, arr)  | cov(acv, acv) |\n",
    "\n",
    "And since $cov(a, a) = var(a)$ the diagonal of this matrix\n",
    "is just a sequence of variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[74.91666667 75.16545427]\n",
      " [75.16545427 75.50980833]]\n",
      "[[77.5        77.75736649]\n",
      " [77.75736649 78.11359482]]\n"
     ]
    }
   ],
   "source": [
    "print(np.cov([arr, acv], ddof=0))\n",
    "print(np.cov([arr, acv], ddof=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful to specify the degrees of freedom,\n",
    "the default `ddof` in variance in NumPy's standard deviation and variance\n",
    "is `ddof=0` but NumPy's covariance attempts to estimate `ddof` by default.\n",
    "If you do not specify a value for the `ddof` argument,\n",
    "NumPy's covariance will end with `ddof=1` in the majority of cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation measure we saw above in the equation\n",
    "is actually just one way of measuring correlation.\n",
    "It is called the Person's correlation coefficient or just Person's $r$.\n",
    "NumPy's `corrcoef` produces a Matrix similar to the covariance method.\n",
    "\n",
    "One important thing to note is that Pearson's correlation coefficient\n",
    "divides out the degrees of freedom in its equation.\n",
    "Therefore, if we are working with a sample, we cannot bias-correct it.\n",
    "`scipy.stats` provides us with a `pearsonr` method,\n",
    "which reminds us of the fact that we cannot bias correct our correlation.\n",
    "It returns an extra $p$ value which is an indication of how\n",
    "likely an uncorrelated dataset is to produce such value of correlation.\n",
    "The $p$ value is just a vague estimate though,\n",
    "just a throw into a *beta* distribution (do not worry if you do not know what that is).\n",
    "In general it can be said that very low $(-1)$ or very high $(1)$\n",
    "value of correlation will give a very small $p$,\n",
    "and correlation values around $0$ will give high $p$.\n",
    "The $p$ value here is just a rough reminder for the experimenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.99937247 0.98441101]\n",
      " [0.99937247 1.         0.98467649]\n",
      " [0.98441101 0.98467649 1.        ]]\n",
      "(0.9993724656859068, 3.582409846684914e-42)\n",
      "(0.9846764927276871, 8.778258288510629e-23)\n",
      "(0.9844110053919739, 1.1146616476882797e-22)\n"
     ]
    }
   ],
   "source": [
    "print(np.corrcoef([arr, acv, acr]))\n",
    "print(stats.pearsonr(arr, acv))\n",
    "print(stats.pearsonr(acv, acr))\n",
    "print(stats.pearsonr(arr, acr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bell Curve](da-bell.svg)\n",
    "\n",
    "<div style=\"text-align:right;\"><sup>da-bell.svg</sup></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the time we need to remember that all these statistics\n",
    "assume the normal distribution of data.\n",
    "A bell shaped distribution, or at least a distribution that\n",
    "just has a single peak - a univariate distribution of data values.\n",
    "A distribution that is multivariate - has several peaks in tis graph - will\n",
    "render the majority of the statistics we see here useless.\n",
    "\n",
    "Next we will see a handful of ideas about distributions,\n",
    "and then a couple of pitfalls in the use of plain statistic values."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
