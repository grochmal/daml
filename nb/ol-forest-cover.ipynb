{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.03 Forest Cover Type\n",
    "\n",
    "In `sklearn` we have `SDGClassifier` which will perform SDG\n",
    "to achieve online learning on top of linear SVMs, logistic regression, or a perceptron.\n",
    "The `SDGRegressor` performs a linear regression as online learning.\n",
    "Note that this means that we can only find solutions to problems\n",
    "that can be approximated linearly.\n",
    "For non-linear online learning we need neural networks (which we will see soon).\n",
    "\n",
    "We import the `SDGCLassifier` and the common preprocessors and validation techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest Cover Type Dataset\n",
    "\n",
    "For a change let's take on a dataset that is not present inside `sklearn`.\n",
    "The forest cover dataset are cartographic data about types of forests\n",
    "in the Roosevelt National Forest in Colorado.\n",
    "Since we are thinking of walking blindfolded around mountain ranges\n",
    "we may as well use a dataset of mountain forest coverage.\n",
    "\n",
    "First let's define a couple of details about the features of the dataset.\n",
    "It has several continuous features and then several categorical ones.\n",
    "The categorical features are already one-hot-encoded for us.\n",
    "The `wild=` areas are quite hidden in the dataset description,\n",
    "for easier access we added comments to the code below describing the features we will load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = [\n",
    "    'Elevation',\n",
    "    'Aspect',\n",
    "    'Slope',\n",
    "    'HHydro',\n",
    "    'VHydro',\n",
    "    'Road',\n",
    "    'Shade_9am',\n",
    "    'Shade_Noon',\n",
    "    'Shade_3pm',\n",
    "    'Fire',\n",
    "]\n",
    "categorical = [\n",
    "    'wild=1',  # Rawah Wilderness Area\n",
    "    'wild=2',  # Neota Wilderness Area\n",
    "    'wild=3',  # Comanche Peak Wilderness Area\n",
    "    'wild=4',  # Cache la Poudre Wilderness Area\n",
    "    'soil=1','soil=2','soil=3','soil=4','soil=5','soil=6','soil=7','soil=8','soil=9','soil=10',\n",
    "    'soil=11','soil=12','soil=13','soil=14','soil=15','soil=16','soil=17','soil=18','soil=19','soil=20',\n",
    "    'soil=21','soil=22','soil=23','soil=24','soil=25','soil=26','soil=27','soil=28','soil=29','soil=30',\n",
    "    'soil=31','soil=32','soil=33','soil=34','soil=35','soil=36','soil=37','soil=38','soil=39','soil=40',\n",
    "]\n",
    "columns = continuous + categorical + ['label']\n",
    "target_names = ['Spruce/Fir', 'Lodgepole Pine', 'Ponderosa Pine',\n",
    "                'Cottonwood/Willow', 'Aspen', 'Douglas-fir', 'Krummholz']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ponderosa Pine Forest Cover](ol-forest-ponderosa-pine.svg)\n",
    "\n",
    "<div style=\"text-align:right;\"><sup>ol-forest-ponderosa-pine.svg</sup></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the features we can then classify an area of forest cover into\n",
    "one of the seven labels.\n",
    "The set has more then half a million rows of data, it a reasonably sized dataset.\n",
    "\n",
    "To keep with the spirit of what we have been doing until now we will\n",
    "write a function to actually retrieve the dataset.\n",
    "We will duplicate the `sklearn` convention for dataset loading and construct\n",
    "our `load_cover_type` function.\n",
    "The function not only allows for easy download of the dataset\n",
    "but also caches the downloaded data on the file system,\n",
    "so one does not need to download it the next time.\n",
    "A couple of things worth mentioning are that:\n",
    "the dataset is taken from the\n",
    "*University of California Irvine Machine Learning Repository*\n",
    "and is kept within their archives g-zipped.\n",
    "The decompression code is a tag obscure but it works on several corner cases.\n",
    "Also, the labels in the dataset start from $1$,\n",
    "we adjust the labels to start from $0$ during the dataset load.\n",
    "\n",
    "This code is pretty much what `sklearn` does every time we call one\n",
    "of its `load_*` procedures to get a dataset.\n",
    "The description of the forest cover dataset is very extensive,\n",
    "we print only the descriptions of the main features to save space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                                     Data Type    Measurement                       Description\n",
      "\n",
      "Elevation                               quantitative    meters                       Elevation in meters\n",
      "Aspect                                  quantitative    azimuth                      Aspect in degrees azimuth\n",
      "Slope                                   quantitative    degrees                      Slope in degrees\n",
      "Horizontal_Distance_To_Hydrology        quantitative    meters                       Horz Dist to nearest surface water features\n",
      "Vertical_Distance_To_Hydrology          quantitative    meters                       Vert Dist to nearest surface water features\n",
      "Horizontal_Distance_To_Roadways         quantitative    meters                       Horz Dist to nearest roadway\n",
      "Hillshade_9am                           quantitative    0 to 255 index               Hillshade index at 9am, summer solstice\n",
      "Hillshade_Noon                          quantitative    0 to 255 index               Hillshade index at noon, summer soltice\n",
      "Hillshade_3pm                           quantitative    0 to 255 index               Hillshade index at 3pm, summer solstice\n",
      "Horizontal_Distance_To_Fire_Points      quantitative    meters                       Horz Dist to nearest wildfire ignition points\n",
      "Wilderness_Area (4 binary columns)      qualitative     0 (absence) or 1 (presence)  Wilderness area designation\n",
      "Soil_Type (40 binary columns)           qualitative     0 (absence) or 1 (presence)  Soil Type designation\n",
      "Cover_Type (7 types)                    integer         1 to 7                       Forest Cover Type designation\n",
      "\n",
      "Forest Cover Type Classes:\t1 -- Spruce/Fir\n",
      "                                2 -- Lodgepole Pine\n",
      "                                3 -- Ponderosa Pine\n",
      "                                4 -- Cottonwood/Willow\n",
      "                                5 -- Aspen\n",
      "                                6 -- Douglas-fir\n",
      "                                7 -- Krummholz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import zlib\n",
    "import requests\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import Bunch\n",
    "\n",
    "\n",
    "def load_cover_type():\n",
    "    cov_dir = 'uci_cover_type'\n",
    "    data_dir = datasets.get_data_home()\n",
    "    data_path = os.path.join(data_dir, cov_dir, 'covtype.data')\n",
    "    descr_path = os.path.join(data_dir, cov_dir, 'covtype.info')\n",
    "    cov_data_gz = 'https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz'\n",
    "    cov_descr = 'https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.info'\n",
    "    os.makedirs(os.path.join(data_dir, cov_dir), exist_ok=True)\n",
    "    try:\n",
    "        with open(descr_path, 'r') as f:\n",
    "            descr = f.read()\n",
    "    except IOError:\n",
    "        print('Downloading file from', cov_descr, file=sys.stderr)\n",
    "        r = requests.get(cov_descr)\n",
    "        with open(descr_path, 'w') as f:\n",
    "            f.write(r.text)\n",
    "        descr = r.text\n",
    "        r.close()\n",
    "    try:\n",
    "        data = pd.read_csv(data_path, delimiter=',', names=columns)\n",
    "    except IOError:\n",
    "        print('Downloading file from', cov_data_gz, file=sys.stderr)\n",
    "        r = requests.get(cov_data_gz)\n",
    "        cov_data = zlib.decompress(r.content, wbits=16+zlib.MAX_WBITS)  # obscure but works\n",
    "        cov_data = cov_data.decode('utf8')\n",
    "        with open(data_path, 'w') as f:\n",
    "            f.write(cov_data)\n",
    "        r.close()\n",
    "        data = pd.read_csv(data_path, delimiter=',', names=columns)\n",
    "    X = data[continuous + categorical].values\n",
    "    y = data['label'].values - 1\n",
    "    return Bunch(DESCR=descr,\n",
    "                 data=X,\n",
    "                 feature_names=columns[:-1],\n",
    "                 feature_continuous=continuous,\n",
    "                 feature_categorical=categorical,\n",
    "                 target=y,\n",
    "                 target_names=target_names)\n",
    "\n",
    "\n",
    "covtype = load_cover_type()\n",
    "print(covtype.DESCR[6923:8554])\n",
    "print()\n",
    "print(covtype.DESCR[12373:12713])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick look at the dataset is always a good idea.\n",
    "One can see all three parts of the set:\n",
    "the continuous features, the one-hot-encoded categorical features,\n",
    "and the forest cover type labels.\n",
    "\n",
    "In the loading function we have also added a distinction between\n",
    "continuous and categorical features.\n",
    "This concept is often useful as one may need to scale continuous\n",
    "features but scaling one-hot-encoded features makes little sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>HHydro</th>\n",
       "      <th>VHydro</th>\n",
       "      <th>Road</th>\n",
       "      <th>Shade_9am</th>\n",
       "      <th>Shade_Noon</th>\n",
       "      <th>Shade_3pm</th>\n",
       "      <th>Fire</th>\n",
       "      <th>...</th>\n",
       "      <th>soil=31</th>\n",
       "      <th>soil=32</th>\n",
       "      <th>soil=33</th>\n",
       "      <th>soil=34</th>\n",
       "      <th>soil=35</th>\n",
       "      <th>soil=36</th>\n",
       "      <th>soil=37</th>\n",
       "      <th>soil=38</th>\n",
       "      <th>soil=39</th>\n",
       "      <th>soil=40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581007</th>\n",
       "      <td>2396</td>\n",
       "      <td>153</td>\n",
       "      <td>20</td>\n",
       "      <td>85</td>\n",
       "      <td>17</td>\n",
       "      <td>108</td>\n",
       "      <td>240</td>\n",
       "      <td>237</td>\n",
       "      <td>118</td>\n",
       "      <td>837</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581008</th>\n",
       "      <td>2391</td>\n",
       "      <td>152</td>\n",
       "      <td>19</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "      <td>95</td>\n",
       "      <td>240</td>\n",
       "      <td>237</td>\n",
       "      <td>119</td>\n",
       "      <td>845</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581009</th>\n",
       "      <td>2386</td>\n",
       "      <td>159</td>\n",
       "      <td>17</td>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>236</td>\n",
       "      <td>241</td>\n",
       "      <td>130</td>\n",
       "      <td>854</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581010</th>\n",
       "      <td>2384</td>\n",
       "      <td>170</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>230</td>\n",
       "      <td>245</td>\n",
       "      <td>143</td>\n",
       "      <td>864</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581011</th>\n",
       "      <td>2383</td>\n",
       "      <td>165</td>\n",
       "      <td>13</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>231</td>\n",
       "      <td>244</td>\n",
       "      <td>141</td>\n",
       "      <td>875</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581012 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Elevation  Aspect  Slope  HHydro  VHydro  Road  Shade_9am  Shade_Noon  \\\n",
       "0            2596      51      3     258       0   510        221         232   \n",
       "1            2590      56      2     212      -6   390        220         235   \n",
       "2            2804     139      9     268      65  3180        234         238   \n",
       "3            2785     155     18     242     118  3090        238         238   \n",
       "4            2595      45      2     153      -1   391        220         234   \n",
       "...           ...     ...    ...     ...     ...   ...        ...         ...   \n",
       "581007       2396     153     20      85      17   108        240         237   \n",
       "581008       2391     152     19      67      12    95        240         237   \n",
       "581009       2386     159     17      60       7    90        236         241   \n",
       "581010       2384     170     15      60       5    90        230         245   \n",
       "581011       2383     165     13      60       4    67        231         244   \n",
       "\n",
       "        Shade_3pm  Fire  ...  soil=31  soil=32  soil=33  soil=34  soil=35  \\\n",
       "0             148  6279  ...        0        0        0        0        0   \n",
       "1             151  6225  ...        0        0        0        0        0   \n",
       "2             135  6121  ...        0        0        0        0        0   \n",
       "3             122  6211  ...        0        0        0        0        0   \n",
       "4             150  6172  ...        0        0        0        0        0   \n",
       "...           ...   ...  ...      ...      ...      ...      ...      ...   \n",
       "581007        118   837  ...        0        0        0        0        0   \n",
       "581008        119   845  ...        0        0        0        0        0   \n",
       "581009        130   854  ...        0        0        0        0        0   \n",
       "581010        143   864  ...        0        0        0        0        0   \n",
       "581011        141   875  ...        0        0        0        0        0   \n",
       "\n",
       "        soil=36  soil=37  soil=38  soil=39  soil=40  \n",
       "0             0        0        0        0        0  \n",
       "1             0        0        0        0        0  \n",
       "2             0        0        0        0        0  \n",
       "3             0        0        0        0        0  \n",
       "4             0        0        0        0        0  \n",
       "...         ...      ...      ...      ...      ...  \n",
       "581007        0        0        0        0        0  \n",
       "581008        0        0        0        0        0  \n",
       "581009        0        0        0        0        0  \n",
       "581010        0        0        0        0        0  \n",
       "581011        0        0        0        0        0  \n",
       "\n",
       "[581012 rows x 54 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(covtype.data, columns=covtype.feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cottonwood Forest Cover](ol-forest-cottonwood.svg)\n",
    "\n",
    "<div style=\"text-align:right;\"><sup>ol-forest-cottonwood.svg</sup></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Half a million rows is a good dataset.\n",
    "It perhaps does not require online learning on most machines\n",
    "but on some it might.\n",
    "\n",
    "That said, for presentation purposes it may take too long\n",
    "to run out code on the full dataset.\n",
    "Instead we will take two forest types: Aspen (label $4$) and Douglas-fir (label $5$),\n",
    "and use only the part of the dataset with these labels.\n",
    "Note how we change the labels to be $0$ and $1$\n",
    "for a classification between only two forest types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>HHydro</th>\n",
       "      <th>VHydro</th>\n",
       "      <th>Road</th>\n",
       "      <th>Shade_9am</th>\n",
       "      <th>Shade_Noon</th>\n",
       "      <th>Shade_3pm</th>\n",
       "      <th>Fire</th>\n",
       "      <th>...</th>\n",
       "      <th>soil=31</th>\n",
       "      <th>soil=32</th>\n",
       "      <th>soil=33</th>\n",
       "      <th>soil=34</th>\n",
       "      <th>soil=35</th>\n",
       "      <th>soil=36</th>\n",
       "      <th>soil=37</th>\n",
       "      <th>soil=38</th>\n",
       "      <th>soil=39</th>\n",
       "      <th>soil=40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2606</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>270</td>\n",
       "      <td>5</td>\n",
       "      <td>633</td>\n",
       "      <td>222</td>\n",
       "      <td>225</td>\n",
       "      <td>138</td>\n",
       "      <td>6256</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2605</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>234</td>\n",
       "      <td>7</td>\n",
       "      <td>573</td>\n",
       "      <td>222</td>\n",
       "      <td>230</td>\n",
       "      <td>144</td>\n",
       "      <td>6228</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26855</th>\n",
       "      <td>2596</td>\n",
       "      <td>36</td>\n",
       "      <td>22</td>\n",
       "      <td>210</td>\n",
       "      <td>-3</td>\n",
       "      <td>514</td>\n",
       "      <td>212</td>\n",
       "      <td>186</td>\n",
       "      <td>100</td>\n",
       "      <td>1200</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26856</th>\n",
       "      <td>2588</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>212</td>\n",
       "      <td>-2</td>\n",
       "      <td>511</td>\n",
       "      <td>218</td>\n",
       "      <td>185</td>\n",
       "      <td>91</td>\n",
       "      <td>1201</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26857</th>\n",
       "      <td>2579</td>\n",
       "      <td>48</td>\n",
       "      <td>21</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>222</td>\n",
       "      <td>190</td>\n",
       "      <td>92</td>\n",
       "      <td>1203</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26858</th>\n",
       "      <td>2571</td>\n",
       "      <td>55</td>\n",
       "      <td>21</td>\n",
       "      <td>228</td>\n",
       "      <td>-2</td>\n",
       "      <td>492</td>\n",
       "      <td>227</td>\n",
       "      <td>190</td>\n",
       "      <td>86</td>\n",
       "      <td>1206</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26859</th>\n",
       "      <td>2638</td>\n",
       "      <td>147</td>\n",
       "      <td>13</td>\n",
       "      <td>210</td>\n",
       "      <td>38</td>\n",
       "      <td>524</td>\n",
       "      <td>237</td>\n",
       "      <td>238</td>\n",
       "      <td>130</td>\n",
       "      <td>1176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26860 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Elevation  Aspect  Slope  HHydro  VHydro  Road  Shade_9am  Shade_Noon  \\\n",
       "0           2596      51      3     258       0   510        221         232   \n",
       "1           2590      56      2     212      -6   390        220         235   \n",
       "2           2595      45      2     153      -1   391        220         234   \n",
       "3           2606      45      7     270       5   633        222         225   \n",
       "4           2605      49      4     234       7   573        222         230   \n",
       "...          ...     ...    ...     ...     ...   ...        ...         ...   \n",
       "26855       2596      36     22     210      -3   514        212         186   \n",
       "26856       2588      43     22     212      -2   511        218         185   \n",
       "26857       2579      48     21     218       0   510        222         190   \n",
       "26858       2571      55     21     228      -2   492        227         190   \n",
       "26859       2638     147     13     210      38   524        237         238   \n",
       "\n",
       "       Shade_3pm  Fire  ...  soil=31  soil=32  soil=33  soil=34  soil=35  \\\n",
       "0            148  6279  ...        0        0        0        0        0   \n",
       "1            151  6225  ...        0        0        0        0        0   \n",
       "2            150  6172  ...        0        0        0        0        0   \n",
       "3            138  6256  ...        0        0        0        0        0   \n",
       "4            144  6228  ...        0        0        0        0        0   \n",
       "...          ...   ...  ...      ...      ...      ...      ...      ...   \n",
       "26855        100  1200  ...        0        0        0        0        0   \n",
       "26856         91  1201  ...        0        0        0        0        0   \n",
       "26857         92  1203  ...        0        0        0        0        0   \n",
       "26858         86  1206  ...        0        0        0        0        0   \n",
       "26859        130  1176  ...        0        0        0        0        0   \n",
       "\n",
       "       soil=36  soil=37  soil=38  soil=39  soil=40  \n",
       "0            0        0        0        0        0  \n",
       "1            0        0        0        0        0  \n",
       "2            0        0        0        0        0  \n",
       "3            0        0        0        0        0  \n",
       "4            0        0        0        0        0  \n",
       "...        ...      ...      ...      ...      ...  \n",
       "26855        0        0        0        0        0  \n",
       "26856        0        0        0        0        0  \n",
       "26857        0        0        0        0        0  \n",
       "26858        0        0        0        0        0  \n",
       "26859        0        0        0        0        0  \n",
       "\n",
       "[26860 rows x 54 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = covtype.data\n",
    "y = covtype.target\n",
    "X = X[(y == 4) | (y == 5)].copy()\n",
    "y = y[(y == 4) | (y == 5)].copy()\n",
    "y[y == 4] = 0\n",
    "y[y == 5] = 1\n",
    "df = pd.DataFrame(X, columns=covtype.feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Willow Forest Cover](ol-forest-willow.svg)\n",
    "\n",
    "<div style=\"text-align:right;\"><sup>ol-forest-willow.svg</sup></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data we can easily see that the continuous features\n",
    "have very distinct value ranges.\n",
    "And therefore will require scaling.\n",
    "\n",
    "We have the columns that are continuous in an attribute\n",
    "of the loaded dataset.\n",
    "If we now scale only those columns and place them back together\n",
    "with the categorical columns we have a dataset we can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26860, 54)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "X_cont = sc.fit_transform(df[covtype.feature_continuous].values)\n",
    "X_cat = df[covtype.feature_categorical].values\n",
    "X = np.c_[X_cont, X_cat]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a real dataset, we should treat it as a real problem.\n",
    "We take out a test set which we will not touch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And train on the training set with cross-validation.\n",
    "The learning rate we will use will be constant with a value of `eta0=0.001`.\n",
    "Note also that SGD is an optimizer, not a model.\n",
    "The `loss=` argument chooses the model to optimize with SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9438756118118056,\n",
       " Pipeline(memory=None,\n",
       "          steps=[('pca',\n",
       "                  PCA(copy=True, iterated_power='auto', n_components=20,\n",
       "                      random_state=None, svd_solver='auto', tol=0.0,\n",
       "                      whiten=False)),\n",
       "                 ('sgdclassifier',\n",
       "                  SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
       "                                early_stopping=False, epsilon=0.1, eta0=0.001,\n",
       "                                fit_intercept=True, l1_ratio=0.15,\n",
       "                                learning_rate='constant', loss='log',\n",
       "                                max_iter=500, n_iter_no_change=5, n_jobs=None,\n",
       "                                penalty='l2', power_t=0.5, random_state=None,\n",
       "                                shuffle=True, tol=0.1, validation_fraction=0.1,\n",
       "                                verbose=0, warm_start=False))],\n",
       "          verbose=False))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_pipeline(\n",
    "    PCA(n_components=10),\n",
    "    SGDClassifier(loss='log_loss', penalty='l2', max_iter=500, alpha=0.01, tol=0.01,\n",
    "                  learning_rate='constant', eta0=0.001))\n",
    "param_grid = {\n",
    "    'sgdclassifier__alpha': [0.01, 0.1],\n",
    "    'sgdclassifier__tol': [0.01, 0.1],\n",
    "}\n",
    "grid = GridSearchCV(model, param_grid, cv=5)\n",
    "grid.fit(xtrain, ytrain)\n",
    "grid.best_score_, grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Aspen Forest Cover](ol-forest-aspen.svg)\n",
    "\n",
    "<div style=\"text-align:right;\"><sup>ol-forest-aspen.svg</sup></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally evaluate on the test set.\n",
    "And we have quite good scores for both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Aspen       0.92      0.92      0.92      1930\n",
      " Douglas-fir       0.95      0.96      0.96      3442\n",
      "\n",
      "    accuracy                           0.94      5372\n",
      "   macro avg       0.94      0.94      0.94      5372\n",
      "weighted avg       0.94      0.94      0.94      5372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = ['Aspen', 'Douglas-fir']\n",
    "yfit = grid.best_estimator_.predict(xtest)\n",
    "print(classification_report(ytest, yfit, target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Douglas-Fir Forest Cover](ol-forest-douglas-fir.svg)\n",
    "\n",
    "<div style=\"text-align:right;\"><sup>ol-forest-douglas-fir.svg</sup></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey!  That wasn't online learning.\n",
    "\n",
    "Right, it was not.\n",
    "The full dataset may need online learning\n",
    "but out sample of two forest types only fit fine in memory.\n",
    "Yet we can make up the idea of a dataset that is too big\n",
    "by slitting into two sets of data and train SGD in an online fashion.\n",
    "We will *misuse* the `train_test_split` function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov1, cov2, ycov1, ycov2 = train_test_split(X, y, test_size=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also argue that we are facing a real world problem in which\n",
    "we only have a tiny bit of data ($10\\%$) right now.\n",
    "Whilst we wait for our rangers to collect more data for us we need to make\n",
    "do with what we already have and build a model.\n",
    "Later, when our forest rangers return with a lot more data,\n",
    "we will be able to use online learning to update the model.\n",
    "\n",
    "In `sklearn` there are two ways of using online learning.\n",
    "One is to use a method called `partial_fit`, instead of `fit`,\n",
    "which will update parameters instead of fitting completely new ones.\n",
    "Another way to enable online learning is to pass `warm_start=True`,\n",
    "this forces `fit` to always work like `partial_fit`.\n",
    "Both methods only work on models that support online learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.957787481804949"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain1, xtest1, ytrain1, ytest1 = train_test_split(cov1, ycov1, test_size=0.2)\n",
    "model = make_pipeline(\n",
    "    PCA(n_components=10),\n",
    "    SGDClassifier(loss='log_loss', penalty='l2', max_iter=500, alpha=0.01, tol=0.01,\n",
    "                  learning_rate='constant', eta0=0.001, warm_start=True))\n",
    "model.fit(xtrain1, ytrain1)\n",
    "yfit = model.predict(xtest1)\n",
    "f1_score(ytest1, yfit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know about a tiny bit of the data and we can, more-or-less, classify that.\n",
    "Note that since we know that we have rather similar scores for both classes\n",
    "on this dataset we are fine using a single score here.\n",
    "\n",
    "But if we try to classify the data we do not know about we may run into trouble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9489121676067687"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain2, xtest2, ytrain2, ytest2 = train_test_split(cov2, ycov2, test_size=0.2)\n",
    "yfit = model.predict(xtest2)\n",
    "f1_score(ytest2, yfit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model without the extra data provided later by the rangers works quite reasonably.\n",
    "\n",
    "But we can train with the extra data and see if things improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9572925060435133"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain2, ytrain2)\n",
    "yfit = model.predict(xtest2)\n",
    "f1_score(ytest2, yfit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Krummholz Forest Cover](ol-forest-krummholz.svg)\n",
    "\n",
    "<div style=\"text-align:right;\"><sup>ol-forest-krummholz.svg</sup></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: Non-GD Optimisation\n",
    "\n",
    "We saw SGD and said that it is the most often used optimization technique.\n",
    "But what are the others?\n",
    "One technique is **simulated annealing** which works by slow cooling.\n",
    "The simulated annealing technique tries random neighbors at each iteration and keeps\n",
    "track of of the point with the lowest value of the error/cost function.\n",
    "The search space for a new neighbor (i.e. the maximum distance form the lowest point\n",
    "found until now) reduces at each iteration.\n",
    "This is similar to SGD with a decreasing learning rate.\n",
    "\n",
    "But there are more techniques.\n",
    "Notably **swarm intelligence** provides us with several optimization algorithms:\n",
    "\n",
    "- particle swarm\n",
    "- bat swarm\n",
    "- cuckoo search\n",
    "\n",
    "And **genetic algorithms** also work reasonably in an online learning scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[UCI - Forest Cover Type Dataset][1]\n",
    "\n",
    "[1]: https://archive.ics.uci.edu/ml/datasets/Covertype \"UCI Forest Cover Type\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
