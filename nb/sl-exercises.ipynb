{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09.08 Supervised Learning Exercises\n",
    "\n",
    "Exercises rating:\n",
    "\n",
    "★☆☆ - You should be able to based on Python knowledge plus the text.\n",
    "\n",
    "★★☆ - You will need to do extra thinking and some extra reading/searching.\n",
    "\n",
    "★★★ - The answer is difficult to find by a simple search,\n",
    "      requires you to do a considerable amount of extra work by yourself\n",
    "      (feel free to ignore these exercises if you're short on time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Boston dataset is a housing price statistical data from the\n",
    "Boston, Massachusetts area in the $1970$s.\n",
    "The dataset has is non-linear since its features are similarities\n",
    "within differently formed areas within the city.\n",
    "To make things harder the dataset is full of outliers,\n",
    "data produced by measurement error or a by lack of measurement filled with averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import Bunch\n",
    "descr = \"\"\"The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
    "prices and the demand for clean air', J. Environ. Economics & Management,\n",
    "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
    "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
    "pages 244-261 of the latter.\n",
    "\n",
    "Variables in order:\n",
    "CRIM     per capita crime rate by town\n",
    "ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "INDUS    proportion of non-retail business acres per town\n",
    "CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "NOX      nitric oxides concentration (parts per 10 million)\n",
    "RM       average number of rooms per dwelling\n",
    "AGE      proportion of owner-occupied units built prior to 1940\n",
    "DIS      weighted distances to five Boston employment centres\n",
    "RAD      index of accessibility to radial highways\n",
    "TAX      full-value property-tax rate per $10,000\n",
    "PTRATIO  pupil-teacher ratio by town\n",
    "B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "LSTAT    % lower status of the population\n",
    "MEDV     Median value of owner-occupied homes in $1000's\n",
    "\"\"\"\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=r\"\\s+\", skiprows=22, header=None)\n",
    "boston = Bunch(\n",
    "    DESCR=descr,\n",
    "    data=np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]]),\n",
    "    target = raw_df.values[1::2, 2],\n",
    ")\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Build a Linear Regression for the entire dataset (★★☆)\n",
    "\n",
    "Make a pipeline with polynomial features, try $2$, $3$ and $4$ polynomial features.\n",
    "The cross validation score from a linear model should not be good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Attempt a non-linear model a Random Forest (★★☆)\n",
    "\n",
    "Try with $50$, $100$ and $300$ trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Show the differences between the linear and non-linear model (★★★)\n",
    "\n",
    "We now got two cross validated models,\n",
    "each of them estimates the house prices in a different way\n",
    "and produces different values.\n",
    "But how different these values are?\n",
    "Build a histogram of differences between the predictions\n",
    "and between each of the predictions and the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an extra build graphs showing the prediction differences for each feature.\n",
    "One way to do it is to graph the house price on the horizontal axis,\n",
    "be it target or prediction, and the feature on the vertical axis.\n",
    "\n",
    "The feature \"CHAS\" is a binary feature,\n",
    "hence it cannot be compared in such a way.\n",
    "Feel free to ignore this feature.\n",
    "As an extra on top of the extra,\n",
    "find a way to compare the prediction differences on that feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "daml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
