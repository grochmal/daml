{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5047ff15-90df-41e7-a319-b9841c64f569",
   "metadata": {},
   "source": [
    "# One Flew over NLP\n",
    "\n",
    "A quick look through current NLP.\n",
    "We will look a Large Language Models (LLM), so popular in the recent years.\n",
    "And at a more practical library for NLP on a smaller scale - SpaCy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3d1245-1765-449b-9dd8-2db10d149c97",
   "metadata": {},
   "source": [
    "## LLMs\n",
    "\n",
    "GPT, PalM, Galactica, you name it.\n",
    "These popular models require hundreds of years in compute time to train.\n",
    "They learn language patterns which they can later replicate.\n",
    "The complete models contain hundreds of millions of neurons,\n",
    "and are often too expensive to just run, not to mention train on small problems.\n",
    "\n",
    "The [huggingface][hug] hub is one place where one can download\n",
    "reasonably sized pre-trained versions of popular models.\n",
    "These are often cut-to-size versions of the big trained models\n",
    "but with little loss of accuracy.\n",
    "\n",
    "[PyTorch][torch] integrates hunggingface hub as one of its model providers.\n",
    "Please note that this is often experimental code so one needs to fiddle with\n",
    "dependencies themselves.\n",
    "For example, for the following examples we currently need to install:\n",
    "\n",
    "    pip install torch\n",
    "    pip install transformers\n",
    "\n",
    "[hug]: https://huggingface.co/models\n",
    "[torch]: https://pytorch.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39948517-a195-4b44-ac86-2c84b25877d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from torch import nn\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ee1cbc-6b25-47a5-887d-209e735c43fe",
   "metadata": {},
   "source": [
    "Similar to `sklearn` the `pipeline` builds an easy to use interface into the models.\n",
    "\n",
    "The important argument is the `task`,\n",
    "one needs to know the model to use for a given task\n",
    "as most models will only be capable of a few of the tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f06a062-6470-4369-b2e3-a446175f9b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f622a4f1-9320-424d-aaa7-25f58a49bb63",
   "metadata": {},
   "source": [
    "One common task is mask-filling.\n",
    "Based on the context what word is most likely in the place of the mask.\n",
    "\n",
    "Pretty much any BERT based model is capable of this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b42aa1-114c-45c7-b55c-969e9cd48493",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9f0ca3-749f-4e8d-ac85-d4044399711d",
   "metadata": {},
   "source": [
    "And we can try a few masked sentences.\n",
    "\n",
    "The return from the `unmasker` is a list of ranked possibilities for the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4833ab9d-43cf-4884-ada8-6b996e75e25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuckoo = \"One flew over the [MASK] nest\"\n",
    "print(cuckoo)\n",
    "pprint(unmasker(cuckoo))\n",
    "\n",
    "elephant = \"A humongous [MASK] entered the porcelain shop\"\n",
    "print(elephant)\n",
    "pprint(unmasker(elephant))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569b4f6a-326e-4f7c-8fa6-9b75a2ad298b",
   "metadata": {},
   "source": [
    "Masking is foten used to fing new terms for specific words.\n",
    "For example, to find synonyms in text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2715982-6597-40f4-9c71-a45e3bc5ab68",
   "metadata": {},
   "source": [
    "Another task we cam build a pipeline for is text generation.\n",
    "This is a more \"popular\" way to use LLMs for conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5f85fa-785c-445c-a961-f630a2b6423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848dc1f3-d1c6-4a91-89c9-997c0914c422",
   "metadata": {},
   "source": [
    "A text generator produces a conversation-like text based on the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1690f8b0-a2cf-438f-b053-ce65fe331273",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = \"Yesterday I went to town to\"\n",
    "pprint(generator(conversation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9907486a-eb6e-40d2-9445-9e08f45ada87",
   "metadata": {},
   "source": [
    "Note that LLM does not know whether the statements are true or not.\n",
    "The LLM only appears to be clever,\n",
    "it only knows what a human would like to read,\n",
    "not whether that fact is locgical or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d52101-9c51-4983-a69b-28617f43fc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = \"Humans landed on Mars on\"\n",
    "pprint(generator(conversation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e266ac47-311f-419f-8c89-6a25e9a6580e",
   "metadata": {},
   "source": [
    "### The pipeline\n",
    "\n",
    "We call the `pipeline` a pipeline in the cases above because it is composed of more than one model.\n",
    "Similar to the way as we did `PCA` and `k-means` in `sklearn`,\n",
    "the transformers pipeline glues a `tokenizer` and an embedding `model` together.\n",
    "\n",
    "The tokenizer is not too different from `tf-idf` in that it explodes words into hundreds of dimensions.\n",
    "The difference is that the dimensions tell more about the context of the words than in plain `tf-idf`.\n",
    "These high dimensional representations are then called word-embeddings.\n",
    "The models themselves then are huge attention neural nets which take input\n",
    "tokenised into these embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e07e09-ea14-4312-ba9a-4307716b4c60",
   "metadata": {},
   "source": [
    "## Down to Earth NLP\n",
    "\n",
    "A more practical set of NLP tools for common problems is provided by the SpaCy library.\n",
    "SpaCy uses a BERT based model to build embeddings and parts of speech for text.\n",
    "\n",
    "Instead of trying to be a input-output model SpaCy is a library of tools that uses\n",
    "a BERT model trained in several ways.\n",
    "One can then choose with ease how to manually craft an NLP system.\n",
    "\n",
    "Here the `en_core_web_sm` is the pre-trained BERT model that SpaCy should\n",
    "use to tokenize, parse and understand the given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e2d07-3693-435b-a206-860f5499b28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy  # noqa\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"merge_noun_chunks\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0516459-241c-4e59-b471-1190eb27ef24",
   "metadata": {},
   "source": [
    "One common taks for SpaCy is to identify action within a sentence.\n",
    "\n",
    "i.e. find the verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a59e1d-94da-49e6-ae8f-db3ec5238efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = nlp(\"We Flew Over the Cuckoo's Nest\")\n",
    "print(list(sentence))\n",
    "[x.pos_ for x in sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a00b5a7-6c61-42d9-9f49-a4d75ea8caee",
   "metadata": {},
   "source": [
    "Note that the model is context based.\n",
    "In a different context the word \"flew\" is not a verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbbf2f3-5274-48db-b9aa-c77abc80968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = nlp(\"One Flew Over the Cuckoo's Nest\")\n",
    "print(list(sentence))\n",
    "[x.pos_ for x in sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23724e8c-9b76-401f-bd44-5fb939669b22",
   "metadata": {},
   "source": [
    "With a few tricks we can now find the action of the sentence.\n",
    "\n",
    "We will assume that the closest nouns to the verb re the actor and the actioned.\n",
    "There are better ways to do it but this way is easy enough to write."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e53e0f7-170b-483a-a697-508a903c0792",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOUNS = [\"NOUN\", \"PRON\", \"PROPN\"]  # noun, pronoun, proper name\n",
    "sentence = nlp(\"We Flew Over the Cuckoo's Nest\")\n",
    "verbs = [x for x in sentence if x.pos_ == \"VERB\"]\n",
    "actions = []\n",
    "for v in verbs:\n",
    "    left = [le for le in v.lefts if le.pos_ in NOUNS]\n",
    "    right = [ri for ri in v.rights if ri.pos_ in NOUNS]\n",
    "    if left and right:\n",
    "        actions.append(f\"{left[-1]} - {v} -> {right[0]}\")\n",
    "actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe474ce-8075-4ae1-ac3f-e061c3860d09",
   "metadata": {},
   "source": [
    "Let's make a real example.\n",
    "\n",
    "Project Guttenberg is a collection of many books free of copyright.\n",
    "We take Alice's Adventures in Wonderland by Lewis Carol from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388e7b73-b63e-4ce7-af03-e3fb825cf418",
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_in_wonderland = open(\"lewis-carol-alice.txt\", \"r\").read()\n",
    "len(alice_in_wonderland)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7d6ede-7e1e-4ad5-87ae-666a0837cc2b",
   "metadata": {},
   "source": [
    "In plain text the entire book is about 160KBs.\n",
    "\n",
    "We can easily pass that through SpaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9449a038-6777-4b63-a96c-a7f73f13eaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "alice = nlp(alice_in_wonderland)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a948a0b-666c-4d77-9737-ac36f87f8522",
   "metadata": {},
   "source": [
    "Let's have a look at what we got.\n",
    "\n",
    "SpaCy has already separated the text into sentence for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc7b4b6-6ed5-491a-9e49-e67dadf9fe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "list(islice(alice.sents, 3, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb9a62e-b6ab-4262-9145-2a1686307cae",
   "metadata": {},
   "source": [
    "With the exact same technique for finding actions\n",
    "we will search across the entire book.\n",
    "\n",
    "A helper class will aid us in the search later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a465a1a5-4402-426e-9eec-87e4b1d2cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOUNS = [\"NOUN\", \"PRON\", \"PROPN\"]  # noun, pronoun, proper name\n",
    "\n",
    "class Action:\n",
    "    def __init__(self, left, verb, right):\n",
    "        self.left = left\n",
    "        self.verb = verb\n",
    "        self.right = right\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"{self.left} - {self.verb} -> {self.right}\"\n",
    "    \n",
    "    __str__ = __repr__\n",
    "\n",
    "def actions_in_sentence(sentence):\n",
    "    actions = []\n",
    "    verbs = [x for x in sentence if x.pos_ == \"VERB\"]\n",
    "    for v in verbs:\n",
    "        left = [l for l in v.lefts if l.pos_ in NOUNS]\n",
    "        right = [r for r in v.rights if r.pos_ in NOUNS]\n",
    "        if left and right:\n",
    "            actions.append(\n",
    "                Action(\n",
    "                    left[-1].text.replace(\"\\n\", \" \"),\n",
    "                    v.text,\n",
    "                    right[0].text.replace(\"\\n\", \" \"),\n",
    "                )\n",
    "            )\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d8fe49-7880-460b-8875-f7d6b2cc3ef0",
   "metadata": {},
   "source": [
    "For the time beginning run it over 100 setneces only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300548e5-d9bd-4637-932d-669eae168163",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = []\n",
    "for sentence in islice(alice.sents, 100):\n",
    "    actions += actions_in_sentence(sentence)\n",
    "len(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a716e2-0d59-4790-ad0b-14a95f479eec",
   "metadata": {},
   "source": [
    "And that is a number of actions that we can visualise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd8e6bf-d60b-4832-99f2-425d013e7e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in actions:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3013f3-7c06-4781-b959-62a6835c954a",
   "metadata": {},
   "source": [
    "Across the full book we got quite a number of actions.\n",
    "\n",
    "We can now try to figure out how active Alice is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40534165-eb70-4d2a-b846-1d2103450b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = []\n",
    "for sentence in alice.sents:\n",
    "    actions += actions_in_sentence(sentence)\n",
    "len(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdebc17-e9b0-4110-ac49-bfe8d25595fd",
   "metadata": {},
   "source": [
    "This is another simplification:\n",
    "we will not distinguish between the actor and the actioned upon.\n",
    "\n",
    "Statistically this should even out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a039d6c-297e-4ada-9c55-fb75d05b0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([a for a in actions if \"alice\" in a.left.lower() or \"alice\" in a.right.lower()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c4f293-6b05-4dcb-8869-7ff297bff63f",
   "metadata": {},
   "source": [
    "Alice is indeed quite active.\n",
    "\n",
    "We can compare this against other proeminent characters in the book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96903a1-0fc2-444a-a6eb-26e5d8a974ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cheshire_cat = len([a for a in actions if \"cat\" in a.left.lower() or \"cat\" in a.right.lower()])\n",
    "hatter = len([a for a in actions if \"hatter\" in a.left.lower() or \"hatter\" in a.right.lower()])\n",
    "white_rabbit = len([a for a in actions if \"hatter\" in a.left.lower() or \"hatter\" in a.right.lower()])\n",
    "print(f\"Cheshire Cat: {cheshire_cat}\")\n",
    "print(f\"The Hatter: {hatter}\")\n",
    "print(f\"White Rabbit: {white_rabbit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20626d1f-e7f4-4419-bc28-92caf8c75eb2",
   "metadata": {},
   "source": [
    "The above is quite a crude NLP system.\n",
    "A more complete system would require a way to recognise whether the nouns we find\n",
    "are indeed the characters we seek.\n",
    "And also recodnise pronouns refering to the characters.\n",
    "\n",
    "These tow sysmes are most often called Named Entity Recognition (NER)\n",
    "and Correference Resolution (Coref).\n",
    "Both systems are in active research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b924d41-53b4-4a04-bb89-f0823093641a",
   "metadata": {},
   "source": [
    "Andrey Karpathy minGPT (simplified):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f2c3c4-9d49-457f-a9e8-d0982592f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    A vanilla multi-head masked self-attention layer with a projection at the end.\n",
    "    It is possible to use torch.nn.MultiheadAttention here but I am including an\n",
    "    explicit implementation here to show that there is nothing too scary here.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn_k = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.c_attn_q = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.c_attn_v = nn.Linear(config.n_embd, config.n_embd)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        # regularization\n",
    "        self.attn_dropout = nn.Dropout(config.attn_pdrop)\n",
    "        self.resid_dropout = nn.Dropout(config.resid_pdrop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        k  = self.c_attn_k(x)\n",
    "        q  = self.c_attn_q(x)\n",
    "        v  = self.c_attn_v(x)\n",
    "\n",
    "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
    "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        # skip connection\n",
    "        att = att + self.attn_dropout(att)\n",
    "        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
    "        y = y.transpose(1, 2)\n",
    "\n",
    "        # output projection\n",
    "        y = self.resid_dropout(y)\n",
    "        return y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
